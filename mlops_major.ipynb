{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Data Structure and Processing Pipeline (15 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Load the iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Create a data processing class that implements:\n",
    "\n",
    "\n",
    "● Conversion of data to pandas DataFrame with proper column names\n",
    "\n",
    "\n",
    "● Feature scaling using StandardScaler\n",
    "\n",
    "\n",
    "● Train-test split with experiment tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Dataset (first 5 rows):\n",
      "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0          -0.900681          1.019004          -1.340227         -1.315444   \n",
      "1          -1.143017         -0.131979          -1.340227         -1.315444   \n",
      "2          -1.385353          0.328414          -1.397064         -1.315444   \n",
      "3          -1.506521          0.098217          -1.283389         -1.315444   \n",
      "4          -1.021849          1.249201          -1.340227         -1.315444   \n",
      "\n",
      "   target  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n",
      "Train-test split shapes: (120, 4) (30, 4)\n",
      "Feature statistics:\n",
      "        sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
      "count       1.500000e+02      1.500000e+02       1.500000e+02   \n",
      "mean       -1.468455e-15     -1.823726e-15      -1.610564e-15   \n",
      "std         1.003350e+00      1.003350e+00       1.003350e+00   \n",
      "min        -1.870024e+00     -2.433947e+00      -1.567576e+00   \n",
      "25%        -9.006812e-01     -5.923730e-01      -1.226552e+00   \n",
      "50%        -5.250608e-02     -1.319795e-01       3.364776e-01   \n",
      "75%         6.745011e-01      5.586108e-01       7.627583e-01   \n",
      "max         2.492019e+00      3.090775e+00       1.785832e+00   \n",
      "\n",
      "       petal width (cm)      target  \n",
      "count      1.500000e+02  150.000000  \n",
      "mean      -9.473903e-16    1.000000  \n",
      "std        1.003350e+00    0.819232  \n",
      "min       -1.447076e+00    0.000000  \n",
      "25%       -1.183812e+00    0.000000  \n",
      "50%        1.325097e-01    1.000000  \n",
      "75%        7.906707e-01    2.000000  \n",
      "max        1.712096e+00    2.000000  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "class IrisDataProcessor:\n",
    "    def __init__(self):\n",
    "        # Initialize your experiment\n",
    "        self.data = load_iris()\n",
    "        self.df = None\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = None, None, None, None\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # Implement experiment workflow\n",
    "        self.df = pd.DataFrame(self.data.data, columns=self.data.feature_names)\n",
    "        self.df['target'] = self.data.target\n",
    "        scaler = StandardScaler()\n",
    "        features_scaled = scaler.fit_transform(self.df[self.data.feature_names])\n",
    "        self.df[self.data.feature_names] = features_scaled\n",
    "        \n",
    "        X = self.df[self.data.feature_names]        # Train-test split\n",
    "        y = self.df['target']\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        print(\"Processed Dataset (first 5 rows):\\n\", self.df.head())\n",
    "        print(\"Train-test split shapes:\", self.X_train.shape, self.X_test.shape)\n",
    "\n",
    "    def get_feature_stats(self):\n",
    "        stats = self.df.describe()\n",
    "        print(\"Feature statistics:\\n\", stats)\n",
    "\n",
    "# Instantiate and run\n",
    "processor = IrisDataProcessor()\n",
    "processor.prepare_data()\n",
    "processor.get_feature_stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
